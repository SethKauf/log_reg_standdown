{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = seaborn.load_dataset('Titanic')\n",
    "titanic.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-point",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the target 'survived' off from the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'sex' column to a binary where 1 represents female"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-civilian",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a train-test split using all default arguments and random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-syndication",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-respect",
   "metadata": {},
   "source": [
    "We will fit a logistic regression model using only `sex` and `fare`.  Remember that logistic regression uses regularization by default.  That means that scaling will have an effect on the scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a standard scaler to train columns of interest, and transform the test\n",
    "ss = None\n",
    "X_train_sc = None\n",
    "X_test_sc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a logistic regression model with the default arguments and random_state=42\n",
    "lr = None\n",
    "# Fit on the scaled training data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-destruction",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-malawi",
   "metadata": {},
   "source": [
    "The coefficients produced by fitting the model dictate the predictions that the model makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model test predictions\n",
    "y_hat = lr.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-formula",
   "metadata": {},
   "source": [
    "Under the hood, the model is applying a decision threshold to assign a 0 or 1 prediction. \n",
    "For the exercise below, apply a decision threshold of .5 to the predicted probabities, so that you can recreate 0 or 1 predictions stored in y_hat above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these predicted probabilities to 0/1 predictions\n",
    "y_hat_proba = lr.predict_proba(X_test_sc)\n",
    "\n",
    "# Apply threshold here\n",
    "y_hat_by_hand = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (y_hat == y_hat_by_hand).sum() == len(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-encounter",
   "metadata": {},
   "source": [
    "# Stretch Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-aircraft",
   "metadata": {},
   "source": [
    "For the final task, we will recreate the predicted predicted probabilities using the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(log_odd):\n",
    "    \n",
    "    '''\n",
    "    The link function translates a log_odd prediction\n",
    "    and returns a probability of class 1 with a\n",
    "    number between 0 and 1.\n",
    "    '''\n",
    "    \n",
    "    return 1/(1+np.e**(-log_odd))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-essence",
   "metadata": {},
   "source": [
    "In the cell below, use the coef_ and intercept_ attributes from the fit model to calculate the log_odds for each record in the test set. Then pass these log_odds into the sigmoid function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log odds are the output of the dot product of X_test, \n",
    "# a version of the coef_ attribute, plus the interceps_ attribute. \n",
    "log_odds = None\n",
    "\n",
    "# use a list comprehension to apply the sigmoid function to each log_odd.\n",
    "predict_proba_by_hand = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(predict_proba_by_hand, y_hat_proba[:,1]).sum() == 223"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
