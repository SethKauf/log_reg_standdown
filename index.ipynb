{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "serial-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "tracked-capability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.475</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch    fare embarked  class  \\\n",
       "823         1       3  female  27.0      0      1  12.475        S  Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "823  woman       False    E  Southampton   yes  False  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = seaborn.load_dataset('Titanic')\n",
    "titanic.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-appreciation",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "owned-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the target 'survived' off from the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "similar-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "X = titanic.drop('survived', axis=1)\n",
    "y = titanic['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "isolated-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'sex' column to a binary where 1 represents female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "demonstrated-bennett",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    577\n",
       "1    314\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "\n",
    "def sex_converter(sex_element):\n",
    "    \n",
    "    if sex_element == 'female':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "X['sex'] = X['sex'].apply(sex_converter)\n",
    "X.sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-private",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "million-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a train-test split using all default arguments and random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "accessible-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-musician",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-separation",
   "metadata": {},
   "source": [
    "We will fit a logistic regression model using only `sex` and `fare`.  Remember that logistic regression uses regularization by default.  That means that scaling will have an effect on the scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "presidential-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a standard scaler to train columns of interest, and transform the test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cultural-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train[['sex', 'fare']])\n",
    "\n",
    "X_train_sc = ss.transform(X_train[['sex', 'fare']])\n",
    "X_test_sc = ss.transform(X_test[['sex', 'fare']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "serial-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a logistic regression model with the default arguments and random_state=42\n",
    "\n",
    "# Fit on the scaled training data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "operating-adoption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-paste",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-training",
   "metadata": {},
   "source": [
    "The coefficients produced by fitting the model dictate the predictions that the model makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "weighted-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions\n",
    "y_hat = lr.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-habitat",
   "metadata": {},
   "source": [
    "Under the hood, the model is applying a decision threshold to assign a 0 or 1 prediction. \n",
    "For the exercise below, apply a decision threshold of .5 to the predicted probabities, so that you can recreate 0 or 1 predictions stored in y_hat above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "yellow-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these predicted probabilities to 0/1 predictions\n",
    "y_hat_proba = lr.predict_proba(X_test_sc)\n",
    "\n",
    "# Apply threshold here\n",
    "y_hat_by_hand = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "revolutionary-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "# Convert these predicted probabilities to 0/1 predictions\n",
    "y_hat_proba = lr.predict_proba(X_test_sc)\n",
    "\n",
    "# Apply threshold here\n",
    "y_hat_by_hand = (y_hat_proba[:,1] > .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "reported-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (y_hat == y_hat_by_hand).sum() == len(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-facing",
   "metadata": {},
   "source": [
    "# Stretch Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-milton",
   "metadata": {},
   "source": [
    "For the final task, we will recreate the predicted predicted probabilities using the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ongoing-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(log_odd):\n",
    "    \n",
    "    '''\n",
    "    The link function translates a log_odd prediction\n",
    "    and returns a probability of class 1 with a\n",
    "    number between 0 and 1.\n",
    "    '''\n",
    "    \n",
    "    return 1/(1+np.e**(-log_odd))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-peripheral",
   "metadata": {},
   "source": [
    "In the cell below, use the coef_ and intercept_ attributes from the fit model to calculate the log_odds for each record in the test set. Then pass these log_odds into the sigmoid function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dramatic-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log odds are the output of the dot product of X_test, \n",
    "# a version of the coef_ attribute, plus the interceps_ attribute. \n",
    "log_odds = None\n",
    "\n",
    "# use a list comprehension to apply the sigmoid function to each log_odd.\n",
    "predict_proba_by_hand = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "appointed-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "log_odds = X_test_sc.dot(lr.coef_.T) + lr.intercept_\n",
    "predict_proba_by_hand = [sigmoid(log_odd)[0] for log_odd in log_odds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "buried-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(predict_proba_by_hand, y_hat_proba[:,1]).sum() == 223"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
